{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv('RAW_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>59389</td>\n",
       "      <td>45</td>\n",
       "      <td>68585</td>\n",
       "      <td>2003-04-14</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['place potatoes in a large pot of lightly sal...</td>\n",
       "      <td>this is a super easy, great tasting, make ahea...</td>\n",
       "      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amish  tomato ketchup  for canning</td>\n",
       "      <td>44061</td>\n",
       "      <td>190</td>\n",
       "      <td>41706</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['mix all ingredients&amp; boil for 2 1 / 2 hours ...</td>\n",
       "      <td>my dh's amish mother raised him on this recipe...</td>\n",
       "      <td>['tomato juice', 'apple cider vinegar', 'sugar...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739       55   \n",
       "1            a bit different  breakfast pizza   31490       30   \n",
       "2                   all in the kitchen  chili  112140      130   \n",
       "3                          alouette  potatoes   59389       45   \n",
       "4          amish  tomato ketchup  for canning   44061      190   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "2          196586  2005-02-25   \n",
       "3           68585  2003-04-14   \n",
       "4           41706  2002-10-25   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "3  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "4  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
       "4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "2  ['brown ground beef in large pot', 'add choppe...   \n",
       "3  ['place potatoes in a large pot of lightly sal...   \n",
       "4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "2  this modified version of 'mom's' chili was a h...   \n",
       "3  this is a super easy, great tasting, make ahea...   \n",
       "4  my dh's amish mother raised him on this recipe...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
       "2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n",
       "3  ['spreadable cheese with garlic and herbs', 'n...             11  \n",
       "4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags',\n",
       "       'nutrition', 'n_steps', 'steps', 'description', 'ingredients',\n",
       "       'n_ingredients'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                 1\n",
       "id                   0\n",
       "minutes              0\n",
       "contributor_id       0\n",
       "submitted            0\n",
       "tags                 0\n",
       "nutrition            0\n",
       "n_steps              0\n",
       "steps                0\n",
       "description       4979\n",
       "ingredients          0\n",
       "n_ingredients        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.shape\n",
    "recipes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231637, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['name', 'id', 'minutes', 'tags', 'nutrition', 'n_steps', 'steps',\n",
       "       'ingredients', 'n_ingredients'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the description, contributor_id, submitted cols \n",
    "recipes = recipes.drop('description', axis=1)\n",
    "recipes = recipes.drop('contributor_id', axis=1)\n",
    "recipes = recipes.drop('submitted', axis=1)\n",
    "recipes.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['winter squash', 'mexican seasoning', 'mixed ...\n",
       "1    ['prepared pizza crust', 'sausage patty', 'egg...\n",
       "2    ['ground beef', 'yellow onions', 'diced tomato...\n",
       "3    ['spreadable cheese with garlic and herbs', 'n...\n",
       "4    ['tomato juice', 'apple cider vinegar', 'sugar...\n",
       "5    ['milk', 'vanilla ice cream', 'frozen apple ju...\n",
       "6    ['fennel seeds', 'green olives', 'ripe olives'...\n",
       "7    ['pork spareribs', 'soy sauce', 'fresh garlic'...\n",
       "8    ['chocolate sandwich style cookies', 'chocolat...\n",
       "9    ['sugar', 'unsalted butter', 'bananas', 'eggs'...\n",
       "Name: ingredients, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes['ingredients'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['make a choice and proceed with recipe', 'depending on size of squash , cut into half or fourths', 'remove seeds', 'for spicy squash , drizzle olive oil or melted butter over each cut squash piece', 'season with mexican seasoning mix ii', 'for sweet squash , drizzle melted honey , butter , grated piloncillo over each cut squash piece', 'season with sweet mexican spice mix', 'bake at 350 degrees , again depending on size , for 40 minutes up to an hour , until a fork can easily pierce the skin', 'be careful not to burn the squash especially if you opt to use sugar or butter', 'if you feel more comfortable , cover the squash with aluminum foil the first half hour , give or take , of baking', 'if desired , season with salt']\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes['steps'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231637, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231575, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recipe instructions with less than 20 characters are not good recipes\n",
    "empty_instr_ind = [index for i, index in zip(recipes['steps'], recipes.index) if len(i) < 20]\n",
    "recipes = recipes.drop(index = empty_instr_ind).reset_index(drop=True)\n",
    "recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in recipes['n_steps'] if i == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231575\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "print(recipes['ingredients'].size)\n",
    "tmp = [ast.literal_eval(i) for i in recipes['ingredients']]\n",
    "# ingredients = [ast.literal_eval(recipes['ingredients'][i] for i in recipes['ingredients'])]\n",
    "# ingredients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = recipes.drop('ingredients', axis=1)\n",
    "recipes['ingredients'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['winter squash',\n",
       " 'mexican seasoning',\n",
       " 'mixed spice',\n",
       " 'honey',\n",
       " 'butter',\n",
       " 'olive oil',\n",
       " 'salt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes['ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    winter squash; mexican seasoning; mixed spice;...\n",
       "1    prepared pizza crust; sausage patty; eggs; mil...\n",
       "2    ground beef; yellow onions; diced tomatoes; to...\n",
       "3    spreadable cheese with garlic and herbs; new p...\n",
       "4    tomato juice; apple cider vinegar; sugar; salt...\n",
       "Name: ingredient_text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ingredients from their lists and formatting as single strings\n",
    "recipes['ingredient_text'] = ['; '.join(ingredients) for ingredients in recipes['ingredients']]\n",
    "recipes['ingredient_text'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"arriba   baked winter squash mexican style winter squash; mexican seasoning; mixed spice; honey; butter; olive oil; salt ['make a choice and proceed with recipe', 'depending on size of squash , cut into half or fourths', 'remove seeds', 'for spicy squash , drizzle olive oil or melted butter over each cut squash piece', 'season with mexican seasoning mix ii', 'for sweet squash , drizzle melted honey , butter , grated piloncillo over each cut squash piece', 'season with sweet mexican spice mix', 'bake at 350 degrees , again depending on size , for 40 minutes up to an hour , until a fork can easily pierce the skin', 'be careful not to burn the squash especially if you opt to use sugar or butter', 'if you feel more comfortable , cover the squash with aluminum foil the first half hour , give or take , of baking', 'if desired , season with salt']\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = recipes['name'] + ' ' + recipes['ingredient_text'] + ' ' + recipes['steps']\n",
    "all_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Clean_text Function\n",
    "import string\n",
    "import re\n",
    "\n",
    "def clean_text(documents):\n",
    "    cleaned_text = []\n",
    "    for doc in documents:\n",
    "        try:\n",
    "            doc = doc.translate(str.maketrans('', '', string.punctuation)) # Remove Punctuation\n",
    "            doc = re.sub(r'\\d+', '', doc) # Remove Digits\n",
    "            doc = doc.replace('\\n',' ') # Remove New Lines\n",
    "            doc = doc.strip() # Remove Leading White Space\n",
    "            doc = re.sub(' +', ' ', doc) # Remove multiple white spaces\n",
    "            cleaned_text.append(doc)\n",
    "        except Exception as e:\n",
    "            print(doc)\n",
    "    return cleaned_text\n",
    "\n",
    "# Cleaning Text\n",
    "cleaned_text = clean_text(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a bit different breakfast pizza prepared pizza crust sausage patty eggs milk salt and pepper cheese preheat oven to degrees f press dough into the bottom and sides of a inch pizza pan bake for minutes until set but not browned cut sausage into small pieces whisk eggs and milk in a bowl until frothy spoon sausage over baked crust and sprinkle with cheese pour egg mixture slowly over sausage and cheese s p to taste bake minutes or until eggs are set and crust is brown'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tokenization, we will lemmatize the words. This is will help create a denser word embeddings. However, no POS tagging, know entities, or noun_phrases will be parsed and added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen chili ground beef yellow onion dice tomato tomato paste tomato soup rotel tomatoe kidney bean water chili powder ground cumin salt lettuce cheddar cheese brown ground beef large pot add chop onion ground beef brown sautee wilt add ingredient add kidney bean like bean chili cook slow cooker high hour hour low serve cold clean lettuce shred cheese'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Strategies and Code\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "' '.join([token.lemma_ for token in nlp(cleaned_text[2]) if not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Function that lemmatizes words and removes Stop Words\n",
    "def text_tokenizer(documents):\n",
    "    tokenized_documents = []\n",
    "    for doc in documents:\n",
    "        tok_doc = ' '.join([token.lemma_ for token in nlp(doc) if not token.is_stop])\n",
    "        tokenized_documents.append(tok_doc)\n",
    "    return tokenized_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Function to run in parallel\n",
    "def text_tokenizer_mp(doc):\n",
    "    tok_doc = ' '.join([token.lemma_ for token in nlp(doc) if not token.is_stop])\n",
    "    return tok_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  20\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Parallelzing tokenizing process\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pool \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mPool(mp\u001b[39m.\u001b[39mcpu_count())\n\u001b[0;32m----> 3\u001b[0m tokenized_text \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(text_tokenizer_mp, [doc \u001b[39mfor\u001b[39;49;00m doc \u001b[39min\u001b[39;49;00m cleaned_text])\n",
      "File \u001b[0;32m/usr/lib64/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/usr/lib64/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/usr/lib64/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib64/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parallelzing tokenizing process\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "tokenized_text = pool.map(text_tokenizer_mp, [doc for doc in cleaned_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Save the tokenized_text variable as a csv in order to return to it;\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Do not attempt to run the parser above, it will simply take too long\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Reload the csv from file insted\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pd\u001b[39m.\u001b[39mSeries(tokenized_text)\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mtokenized_text.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the tokenized_text variable as a csv in order to return to it;\n",
    "# Do not attempt to run the parser above, it will simply take too long\n",
    "# Reload the csv from file insted\n",
    "pd.Series(tokenized_text).to_csv('tokenized_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tokenized_text = pd.read_csv('tokenized_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         arriba baked winter squash mexican style winte...\n",
       "1         bit different breakfast pizza prepared pizza c...\n",
       "2         kitchen chili ground beef yellow onion dice to...\n",
       "3         alouette potatoe spreadable cheese garlic herb...\n",
       "4         amish tomato ketchup can tomato juice apple ci...\n",
       "                                ...                        \n",
       "231569    zydeco soup celery onion green sweet pepper ga...\n",
       "231570    zydeco spice mix paprika salt garlic powder on...\n",
       "231571    zydeco ya ya devil egg hardcooke egg mayonnais...\n",
       "231572    cookie design cookie stick butter eagle brand ...\n",
       "231573    cookie design sugar shortbread cookies granula...\n",
       "Name: tokenized, Length: 231574, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text['tokenized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Word Embeddings\n",
    "\n",
    "- TF-IDF\n",
    "- Pre-trained GloVe Word Embeddings\n",
    "- GloVe Embeddings trained on the recipe corpora\n",
    "\n",
    "In an attempt to create dense word embeddings, I could find no reliable examples to follow that integrate GloVe or Word2Vec with document topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenized_text['tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231574, 62557)\n",
      "62557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naman/Desktop/ly_project/Recipe-Recommendation-System/venv/lib64/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase = True,\n",
    "                            ngram_range = (1,1))\n",
    "\n",
    "text_tfidf = vectorizer.fit_transform(tokenized_text)\n",
    "tfidf_words = vectorizer.get_feature_names()\n",
    "print(text_tfidf.shape)\n",
    "print(len(tfidf_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231574, 62557)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_components = 50,\n",
    "          n_jobs = -1,\n",
    "          max_iter = 100)\n",
    "text_lda = lda.fit_transform(text_tfidf)\n",
    "text_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
